# -*- coding: utf-8 -*-
"""IrisClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K7kwniucj5QERolsF_yy_jGI4TQKMMaw
"""

# Columns: Id, SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm
# Output: class of iris (Iris-versicolor, Iris-setosa, Iris-virginica)
# 150 rows, 6 cols--( We need 4 ips & 1 op--class)

# Library imports

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Loading the dataset

df = pd.read_csv('Iris.csv')
print(df.shape)
df.head()

df.describe()

# Visualization

# sns.pairplot(df, hue="Species")

# Get the count of each species
species_counts = df['Species'].value_counts()
print(species_counts)

# Create a bar plot using plt.plot()
plt.figure(figsize=(5, 3))  # Adjust the figure size as needed
plt.bar(species_counts.index, species_counts.values, color='skyblue', width=0.5)

# Set the title and labels
plt.title('Count of Each Species')
plt.xlabel('Species')
plt.ylabel('Count')

# Rotate x-axis labels for better readability if needed
# plt.xticks(rotation=45)

# Show plot
# plt.tight_layout()
plt.show()

# Count missing values in each column
missing_values = df.isna().sum()

print("Missing values in each column:")
print(missing_values)

# No missing values, well balanced dataset âœ”

"""# Machine Learning task starts here"""

# Separating features & target

X = df.iloc[:, 1:-1].values  # Id column excluded
y = df.iloc[:, -1].values

# Spliting into train & test sets

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

# Feature Scaling is not necessary here & also it doesn't improves the accuracy_score in this case

# from sklearn.preprocessing import StandardScaler
# sc = StandardScaler()
# X_train = sc.fit_transform(X_train)
# X_test = sc.transform(X_test)

# Training SVM model on the train set

from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0)
classifier.fit(X_train, y_train)

# Making the Confusion Matrix

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)  # same for Logistic Regression, Kernel SVM, KNN, Naive Bayes & DTC

# Predicting individual value

X_new = np.array([[5.8, 3.0, 3.7, 1.2]])

# Make predictions on the new data
prediction = classifier.predict(X_new) # SVM

# Print the predictions
print(prediction)